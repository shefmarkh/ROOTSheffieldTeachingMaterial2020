{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again we use the \"!\" command to specify we want to execute commands via the terminal, outside python\n",
    "#rootls is an example of a root command line tool: \n",
    "#https://root.cern/manual/storing_root_objects/#root-command-line-tools\n",
    "#Allows to run common operations from the linux/mac terminal, without running ROOT or python directly.\n",
    "! rootls ../Lecture1/tree2.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do the same in python we would have to type:\n",
    "from ROOT import TFile\n",
    "myFile = TFile.Open(\"../Lecture1/tree2.root\")\n",
    "#Note the output is a bit more detailed though\n",
    "myFile.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"make\" is a standard command to build an executable, which you can run. An executable can be thought of as a \n",
    "#translation of your computer code into something the computer can understand. When using python this happens in\n",
    "#real time, behind the scenes.\n",
    "#The \"!\" tells Jupyter to run the command in the underlying terminal.\n",
    "! make \n",
    "#You can see the commands \"make\" actually runs printed below.\n",
    "#Lots of options passed to g++ (don't worry about these) - the important part is it creates library files (*.d,*.o)\n",
    "#and eventually an executable which you run (\"myROOTCommand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the command in the terminal, and we see what it does.\n",
    "! ./myROOTCommand ../Lecture1/tree2.root t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also make a python shortcut command!\n",
    "#Note in linux you can skip the \"python3\" part (needed in Jupyter on mybinder!)\n",
    "! python3 ./myROOTCommand.py ../Lecture1/tree2.root t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1\n",
    "#Make your own python shortcut command which draws an arbitrary variable from the TTree in tree2.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now lets use uproot - note there is no c++ version! Python only.\n",
    "import uproot\n",
    "#Load the TTree from the ATLAS open data (note the miniTree variable is NOT of type TTree - we are now\n",
    "#in the uproot ecosystem and not in the ROOT ecosystem\n",
    "miniTreeZmumu = uproot.open(\"http://opendata.atlas.cern/release/samples/MC/mc_147771.Zmumu.root\")[\"mini\"]\n",
    "#Lets print the variables in the TTree\n",
    "miniTreeZmumu.keys()\n",
    "#note these variables are defined at http://opendata.atlas.cern/books/current/openatlasdatatools/_book/variable_names.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose which variables we want to use\n",
    "#For each event with jets, we get an array of size alljet_n (NOT jet_N!)\n",
    "#entry_stop restricts the number of entries to use (just done to make example run faster...)\n",
    "#library set to 'pd' gives us a pandas dataframe\n",
    "df_Zmumu = miniTreeZmumu.arrays([\"alljet_n\",\"jet_pt\"],library='pd',entry_stop=1000)\n",
    "df_Zmumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In my notebook, had to run this cell twice to get the histograms to display...\n",
    "df_Zmumu.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniTreeTTbar = uproot.open(\"http://opendata.atlas.cern/release/samples/MC/mc_117049.ttbar_had.root\")[\"mini\"]\n",
    "df_ttbar = miniTreeTTbar.arrays([\"alljet_n\",\"jet_pt\"],library='pd',entry_stop=1000)\n",
    "df_ttbar.hist(\"jet_pt\",bins=100,range=[0,200000])\n",
    "df_ttbar.hist(\"alljet_n\",bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2\n",
    "#Try making some histograms of other quantities in the open data.\n",
    "#Can you reproduce plots we saw in earlier Lectures with .../Lecture1/tree2.root using uproot and matplotlib?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Zmumu=df_Zmumu.assign(signal=1)\n",
    "df_ttbar=df_ttbar.assign(signal=0)\n",
    "df_list = [df_Zmumu,df_ttbar]\n",
    "import pandas\n",
    "df_all = pandas.concat(df_list)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.hist(\"jet_pt\",bins=100,range=[0,200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.hist(\"signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=2,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_all.values\n",
    "X = dataset[:,0:2]\n",
    "Y = dataset[:,2]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=1,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "for i in range(5000):\n",
    "\tprint('Data of %s was predicted to be %d (and expected to be %d)' % (X[i].tolist(), predictions[i], Y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3\n",
    "#Try using different variables and options and see if you can get something working better\n",
    "#You may need to reset and clear the notebook to get the below to work - some of the above code seems to interfere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/06\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree background of type Background with 1137 events\n",
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree signal of type Signal with 961 events\n",
      "<HEADER>                          : Loading booked method: BDT BDTG\n",
      "                         : \n",
      "                         : the option NegWeightTreatment=InverseBoostNegWeights does not exist for BoostType=Grad\n",
      "                         : --> change to new default NegWeightTreatment=Pray\n",
      "                         : Rebuilding Dataset dataset\n",
      "                         : Building event vectors for type 2 Background\n",
      "                         : Dataset[dataset] :  create input formulas for tree background\n",
      "                         : Building event vectors for type 2 Signal\n",
      "                         : Dataset[dataset] :  create input formulas for tree signal\n",
      "<HEADER> DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Dataset[dataset] : Weight renormalisation mode: \"EqualNumEvents\": renormalises all event classes ...\n",
      "                         : Dataset[dataset] :  such that the effective (weighted) number of events in each class is the same \n",
      "                         : Dataset[dataset] :  (and equals the number of events (entries) given for class=0 )\n",
      "                         : Dataset[dataset] : ... i.e. such that Sum[i=1..N_j]{w_i} = N_classA, j=classA, classB, ...\n",
      "                         : Dataset[dataset] : ... (note that N_j is the sum of TRAINING events\n",
      "                         : Dataset[dataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor!)\n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Background -- training events            : 100\n",
      "                         : Background -- testing events             : 100\n",
      "                         : Background -- training and testing events: 200\n",
      "                         : Signal     -- training events            : 100\n",
      "                         : Signal     -- testing events             : 100\n",
      "                         : Signal     -- training and testing events: 200\n",
      "                         : \n",
      "<HEADER> DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ---------------------------------------------------------\n",
      "                         :                 emFracEnhanced eng_frac_core centerLambda\n",
      "                         : emFracEnhanced:         +1.000        -0.357       -0.666\n",
      "                         :  eng_frac_core:         -0.357        +1.000       +0.363\n",
      "                         :   centerLambda:         -0.666        +0.363       +1.000\n",
      "                         : ---------------------------------------------------------\n",
      "<HEADER> DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ---------------------------------------------------------\n",
      "                         :                 emFracEnhanced eng_frac_core centerLambda\n",
      "                         : emFracEnhanced:         +1.000        -0.017       +0.249\n",
      "                         :  eng_frac_core:         -0.017        +1.000       +0.208\n",
      "                         :   centerLambda:         +0.249        +0.208       +1.000\n",
      "                         : ---------------------------------------------------------\n",
      "<HEADER> DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "<HEADER>                          : Training method BDT BDTG\n",
      "<HEADER>                          : Train method: BDTG for Classification\n",
      "                         : \n",
      "<HEADER> BDTG                     : #events: (reweighted) sig: 100 bkg: 100\n",
      "                         : #events: (unweighted) sig: 100 bkg: 100\n",
      "                         : Training 2000 Decision Trees ... patience please\n",
      "                         : Elapsed time for training with 200 events: 0.0843 sec         \n",
      "<HEADER> BDTG                     : [dataset] : Evaluation of BDTG on training sample (200 events)\n",
      "                         : Elapsed time for evaluation of 200 events: 0.00902 sec       \n",
      "                         : Creating xml weight file: dataset/weights/Classification_BDTG.weights.xml\n",
      "                         : Creating standalone class: dataset/weights/Classification_BDTG.class.C\n",
      "                         : model.root:/dataset/Method_BDT/BDTG\n",
      "<HEADER>                          : Training finished\n",
      "                         : \n",
      "<HEADER>                          : Test all methods\n",
      "<HEADER>                          : Test method: BDTG for Classification performance\n",
      "                         : \n",
      "<HEADER> BDTG                     : [dataset] : Evaluation of BDTG on testing sample (200 events)\n",
      "                         : Elapsed time for evaluation of 200 events: 0.00864 sec       \n",
      "<HEADER>                          : Evaluate classifier: BDTG\n",
      "                         : \n",
      "<HEADER> BDTG                     : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "<HEADER> TFHandler_BDTG           :       Variable              Mean              RMS      [        Min              Max ]\n",
      "                         : -----------------------------------------------------------------------------------------\n",
      "                         : emFracEnhanced:         0.70997         0.35419   [          0.0000          1.0000 ]\n",
      "                         :  eng_frac_core:         0.39976         0.13051   [         0.13353         0.87234 ]\n",
      "                         :   centerLambda:          460.53          451.30   [          0.0000          2132.1 ]\n",
      "                         : -----------------------------------------------------------------------------------------\n",
      "<HEADER> Dataset:dataset          : Created tree 'TestTree' with 200 events\n",
      "                         : \n",
      "<HEADER> Dataset:dataset          : Created tree 'TrainTree' with 200 events\n",
      "                         : \n",
      "                         : --------------------------------------------------- :\n",
      "                         : DataSet              MVA                            :\n",
      "                         : Name:                Method/Title:    ROC-integ     :\n",
      "                         : --------------------------------------------------- :\n",
      "                         : dataset              BDT/BDTG         0.920         :\n",
      "                         : --------------------------------------------------- :\n",
      "                         : -----------------------------------------------------\n",
      "<HEADER>                          : Evaluation done.\n",
      "                         : \n",
      "                         : Jobs = 1 Real Time = 0.302423 \n",
      "                         : -----------------------------------------------------\n",
      "                         : Evaluation done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%, time left: unknown\n",
      "6%, time left: 0 sec\n",
      "12%, time left: 0 sec\n",
      "18%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "31%, time left: 0 sec\n",
      "37%, time left: 0 sec\n",
      "43%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "56%, time left: 0 sec\n",
      "62%, time left: 0 sec\n",
      "68%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "81%, time left: 0 sec\n",
      "87%, time left: 0 sec\n",
      "93%, time left: 0 sec\n",
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n",
      "0%, time left: unknown\n",
      "7%, time left: 0 sec\n",
      "13%, time left: 0 sec\n",
      "19%, time left: 0 sec\n",
      "25%, time left: 0 sec\n",
      "32%, time left: 0 sec\n",
      "38%, time left: 0 sec\n",
      "44%, time left: 0 sec\n",
      "50%, time left: 0 sec\n",
      "57%, time left: 0 sec\n",
      "63%, time left: 0 sec\n",
      "69%, time left: 0 sec\n",
      "75%, time left: 0 sec\n",
      "82%, time left: 0 sec\n",
      "88%, time left: 0 sec\n",
      "94%, time left: 0 sec\n"
     ]
    }
   ],
   "source": [
    "from ROOT import TMVA,TFile\n",
    "#Create a DataLoader object and add signal and backgrond TTree to it\n",
    "dataLoader = TMVA.DataLoader(\"dataset\")\n",
    "#We use a ROOT file with both signal and background trees - these correspond to signal and background classified\n",
    "#calorimeter clusters\n",
    "myFile = TFile.Open(\"MVATree_FirstEvent_0_LastEvent_10000.root\")\n",
    "signalTree = myFile.Get(\"signal;1\")\n",
    "backgroundTree = myFile.Get(\"background;1\")\n",
    "dataLoader.AddBackgroundTree(backgroundTree)\n",
    "dataLoader.AddSignalTree(signalTree)\n",
    "#Choose some variables to use in our classifier (BDT, NN etc)\n",
    "dataLoader.AddVariable(\"emFracEnhanced\",'F')\n",
    "#dataLoader.AddVariable(\"emFracEnhanced\",'F')\n",
    "dataLoader.AddVariable(\"eng_frac_core\",'F')\n",
    "dataLoader.AddVariable(\"centerLambda\",'F')\n",
    "outputFile = TFile(\"model.root\",\"RECREATE\")\n",
    "classification = TMVA.Experimental.Classification(dataLoader,outputFile,\"Jobs=1\")\n",
    "classification.BookMethod(TMVA.Types.kBDT, \"BDTG\", \"!H:!V:NTrees=2000:MinNodeSize=2.5%:BoostType=Grad:Shrinkage=0.10:\"\n",
    "                                             \"UseBaggedBoost:BaggedSampleFraction=0.5:nCuts=20:MaxDepth=2\")\n",
    "#Restrict how many events we use for testing and training (const TCut &cut, Int_t NsigTrain, Int_t NbkgTrain, \n",
    "#Int_t NsigTest, Int_t NbkgTest)\n",
    "dataLoader.PrepareTrainingAndTestTree(\"\",100,100,100,100)\n",
    "classification.Evaluate()\n",
    "outputFile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a vector of results (of size 1 in our case because we only trained one classifier)\n",
    "results = classification.GetResults()\n",
    "#Get a ROC graph and draw it\n",
    "BDT_ROC_Graph = results[0].GetROCGraph()\n",
    "from ROOT import TCanvas\n",
    "canPython = TCanvas()\n",
    "BDT_ROC_Graph.Draw()\n",
    "canPython.Draw()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Task 4 - take a look in the ROOT TTree and try different variable choices, different numbers of variables etc to see how it alters the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
